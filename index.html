<html> <head>

<title>RL Snake</title> 
<style type="text/css">
<!--

li a{
color: #989898; 
}
li a:visited {
color: #989898;
}

li a:hover {
color: #000000;
}

body{
background: #FFFFFF;
color: black;
       font-family: sans-serif;
       margin-left:0.6em;
width:800px;
}

ul li{
	list-style:disc;
color: black;
       font-size:0.9em;
}

ul ul li{
	list-style:disc;
color:black;
}

.heading{
color: #1a6ed5;
       font-size:0.95em;
}

.author{
color: #172380;
margin:1em;
       margin-left:0em;
}

.enumerate{
color: #0F386B;
display:inline;
}
.version{
color: black;
display:inline;
margin:0.5em;
       margin-left:0em;
}

.date{
color: #228a73;
       font-size:0.9em;
}

p, ol{
	font-size:0.9em;
}

h2, h4{
color: #3b61c3;
}

pre{
            background: #edf3ff;
	    margin-top:0.7em;
	    margin-bottom:0.7em;
	    padding-top: 1em;
	    padding-bottom: 1em;
}

em{
color: #1a8a4f;
       font-style:normal;
       font-weight:bolder;
}

.green {
	color: rgb(0, 0, 240);
}

.footer{
	margin-top:1em;
	padding-top:0.5em;
	border-top: 1px solid #131b6f;
	font-size:0.85em;
}
</style>

</head>


<body> 
<h2> RL Snake </h2>

<h4>Reinforcement Learning in the Classic Snake Arcade Game.</h4>

<div class ="author">Pranesh Srinivasan</div>

<div class = "heading">Description</div>
<p> Reinforcement Learning (<a
href="http://en.wikipedia.org/wiki/Q-learning">Q-Learning</a> & <a
href="http://en.wikipedia.org/wiki/SARSA">SARSA</a>) applied to the snake game
--- My course project for the Reinforcement Learning course.
</p>

<div class = "heading">Why is it not just another snake bot?</div>
<p>
In Reinforcement Learning, one does not <i>teach</i> the agent (bot). The
agent's controller (the environment) merely tells it what is good, and what is
bad. This particular agent has been told that:

<ul>
<li> Getting food is good. +500 points to the snake. </li>
<li> Hitting a wall or itself is bad. -100 reward to it.</li>
<li> Anything else is also (relatively) bad. We want to get to the food
quickly. (-10 to the snake for every move where none of the above happens).<em>[1]</em> </li>
</ul>

</p><p>
The snake then learns on its own, through a process of trial-and-error across
many games, what it should do, and what it should not. It is kind of like human
learning<em>[2]</em>.
</p>

<div class = "heading">How does it work?</div>
<p> Source can be found on <a href="http://www.github.com/spranesh/rl-snake">github</a>. </p>To download simply run
<pre>
$ git clone https://github.com/spranesh/rl-snake.git 
</pre>


<p> Watch these three (bad quality) screencasts for examples:

<ul>
<li> <a href="plain.gif">Plain Old Snake.</a> (Q Learning)</li>
<li> <a href="middle_wall.gif">Snake with a small wall in between.</a> (Q Learning)</li>
<li> <a href="vertical-maze.gif">A crazy vertical maze.</a> (SARSA)</li>
</ul>

<br />
<br />
<div class="heading"> Observations </div>
<p>
SARSA seems to peform better. It however needs quite a lot more training. The
new <tt>long_train.sara training</tt> file in the source, was the result of
training SARSA for 8 hours (~30,000 games). Q-Learning does well (compared to
SARSA), when the training period is short - 15-20 minutes on my machine seems
ideal.

</p><p>
Both algorithms show a bit of learning, even with just 2-3 (~100 games) minutes
of training. This is mainly due to the compact state space used
(<tt>state_mappers/quadrant_view.py</tt>). It has been seen to be sufficient to
merely store which quadrant (relative to the snake) the food is in. Exact
position, leads to a huge increase in the size of the state space, decreasing
the rate of learning.

</p><p>
Note: Unlike most RL Algorithms, a completely relative state space has been
used for this problem. The world changes with respect to the snake's head.
</p>

<br />
<br />
<small>
<p>
<em>[1]</em>:Thanks to <a href="http://www.facebook.com/Prashanth.Srinivasan0">Prashanth</a>
for seeing through a reward bug that I was banging my head on.
</p><p>
<em>[2]</em>: Strong correlations have been observed by the models reinforcement
learning uses, and the reinforcement happening in our neurons. <a
href="http://en.wikipedia.org/wiki/Temporal_difference_learning">TD
Learning</a> is one such model.
</p>

<br />
<br />
<br />

<iframe src="http://www.facebook.com/plugins/like.php?href=http%3A%2F%2Fwww.cse.iitm.ac.in%2F%7Espranesh%2Fprojects%2Frl-snake%2F&amp;layout=standard&amp;show_faces=true&amp;width=450&amp;action=like&amp;colorscheme=light&amp;height=80" scrolling="no" frameborder="0" style="border:none; overflow:hidden; width:450px; height:80px;" allowTransparency="true"></iframe>

</body></html>
